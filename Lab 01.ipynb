{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os, pathlib, warnings, urllib, shutil\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "giturl = \"https://github.com/dicodingacademy/assets/releases/download/release/\"\n",
    "\n",
    "dataset = \"rockpaperscissors.zip\"\n",
    "\n",
    "urllib.request.urlretrieve(os.path.join(giturl, dataset), dataset)\n",
    "\n",
    "shutil.unpack_archive('rockpaperscissors.zip', '/content', 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "root = \"/content/rockpaperscissors/rps-cv-images\"\n",
    "\n",
    "os.listdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "rescale = 1.0 / 255.0\n",
    "\n",
    "trainset = ImageDataGenerator(\n",
    "  rescale = rescale,\n",
    "  fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "validset = ImageDataGenerator(rescale=rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "total_batch = 128\n",
    "\n",
    "train = trainset.flow_from_directory(\n",
    "  root,\n",
    "  target_size = (150, 150),\n",
    "  class_mode = \"categorical\",\n",
    "  batch_size = total_batch,\n",
    "  subset = \"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "labeler = list(train.class_indices.keys())\n",
    "\n",
    "labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "valid = validset.flow_from_directory(\n",
    "  root,\n",
    "  target_size = (150, 150),\n",
    "  class_mode = \"categorical\",\n",
    "  batch_size = total_batch,\n",
    "  subset = \"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Conv2D(16, 3, activation=\"relu\", input_shape=(150, 150, 3)),\n",
    "  layers.MaxPool2D((2, 2)),\n",
    "  layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "  layers.MaxPool2D((2, 2)),\n",
    "  layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "  layers.MaxPool2D((2, 2)),\n",
    "  layers.Flatten(),\n",
    "  layers.Dropout(0.3),\n",
    "  layers.Dense(128, activation=\"relu\"),\n",
    "  layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "loss = \"categorical_crossentropy\"\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=10, validation_data=valid)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
